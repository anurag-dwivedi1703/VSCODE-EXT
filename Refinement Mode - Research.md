Architectural Blueprint for Agentic Requirement Refinement in Integrated Development EnvironmentsExecutive Summary: The Era of "Mission Control" DevelopmentThe software development landscape is currently undergoing a seismic shift, transitioning from the paradigm of "AI-as-Copilot"—where Large Language Models (LLMs) function primarily as sophisticated autocomplete engines—to "AI-as-Architect," where autonomous agents orchestrate complex, multi-step engineering workflows. This evolution is epitomized by platforms like Google's Antigravity and Project IDX, which introduce the concept of "Mission Control": a centralized interface where developers manage agents that plan, reason, and execute tasks asynchronously. However, a critical bottleneck remains in this new operational model: the Prompt Ambiguity Problem.While modern LLMs possess the coding proficiency of senior engineers, their output is often compromised by the vague, underspecified, or context-poor nature of initial user prompts. A user request to "add a login page" contains implicit assumptions about authentication protocols, database schemas, and UI component libraries that, if left unstated, lead to hallucinated implementations and technical debt. To bridge this gap, your Visual Studio Code (VS Code) extension—already equipped with planning capabilities and codebase awareness—must implement a rigorous Refinement Mode.This report provides an exhaustive architectural framework for building this multi-turn refinement mode. It proposes a Critic-Refiner Cognitive Architecture, leveraging specialized agent personas (The Product Manager, The Architect, The Curator) to elicit latent requirements using Maieutic Prompting and validate them against the existing codebase via AST-Enhanced Retrieval Augmented Generation (RAG). The objective is to transform the user's raw intent into a "Golden Prompt"—a technically sound, design-compliant specification (PRD or Gherkin) that guarantees high-fidelity code generation. By treating the prompt as a software artifact that must be "compiled" and "debugged" before execution, we shift the cognitive load of quality assurance from the coding phase to the planning phase, significantly reducing the cost of error.1. The Imperative of Requirement Refinement in Agentic Workflows1.1 The "Context Gap" and the Failure of One-Shot GenerationThe prevailing interaction model in current AI coding tools is "one-shot" generation: the user provides a natural language prompt, and the model immediately attempts to generate a solution. While effective for isolated functions or boilerplate, this approach collapses under the weight of complex software engineering tasks. Research indicates that one-shot prompts frequently fail to capture the "invisible" constraints of a software project—the implicit design patterns, security policies, and architectural decisions that are not explicitly stated in the prompt but are evident in the codebase.This discrepancy is known as the Context Gap. When a user asks an AI to "refactor the API," the AI lacks the user's mental model of why the refactor is needed (e.g., performance vs. readability) and how it should align with the system's long-term goals. Without a refinement phase, the AI defaults to the probabilistic mean of its training data, producing generic code that may function syntactically but fails architecturally. For instance, it might introduce a new library for state management when the project strictly enforces a different pattern, creating "architectural drift".1.2 The Economic Case for "Thinking Slow"In behavioral economics and cognitive science, "System 1" thinking is fast, intuitive, and prone to error, while "System 2" is slow, deliberative, and logical. Current AI coding assistants operate primarily in System 1 mode. The proposed Refinement Mode introduces a System 2 layer—a "Reasoning Loop" that pauses execution to verify intent.The economic justification for this latency is found in the "Shift Left" principle of software testing: a bug found during the requirements phase costs 100x less to fix than a bug found in production. Similarly, an ambiguity resolved during the prompt refinement phase prevents the generation of thousands of lines of incorrect code that the user must then manually debug. By investing computation time in the planning phase (Theorist -> Critic -> Refiner), we achieve a net reduction in the "Time-to-Valid-Code" metric, despite the initial delay.1.3 The Google Antigravity "Mission Control" PhilosophyYour extension aims to emulate the "Mission Control" experience of Google Antigravity. This philosophy redefines the IDE not as a text editor, but as an orchestration platform. In this model, the user acts as the Architect, defining high-level objectives, while the AI agents act as the Engineering Team, handling the implementation details.Key tenets of this philosophy that must inform the Refinement Mode include:Trust through Transparency: The user must see how the agent is interpreting the requirement. The Refinement Mode should not be a black box; it must produce visible artifacts (plans, diagrams, specs) that the user can inspect.Autonomy with Guardrails: Agents should be autonomous in planning but require explicit approval for execution. The Refinement Mode creates the "contract" for this execution.Asynchronous Feedback: The refinement process should not block the editor. It should happen in a dedicated "Mission Control" view (e.g., a Webview or Chat Panel), allowing the user to continue working while the agents deliberate.2. Architectural Framework: The Critic-Refiner LoopThe core engine of the Refinement Mode is the Critic-Refiner architectural pattern. Unlike a linear chain where prompts flow sequentially, this pattern creates a cyclical workflow where requirements are iteratively improved through adversarial evaluation. This mimics the dynamic of a human engineering team, where a Product Manager's requirements are critiqued by a Tech Lead before being handed to a Developer.2.1 The Multi-Agent EnsembleTo achieve high-fidelity refinement, we must decompose the reasoning process into specialized agent roles. A single monolithic system prompt often suffers from "attention dilution," where the model forgets specific constraints (like security or style) while trying to be creative. By using distinct personas, we force the system to adopt different cognitive lenses.Agent PersonaRolePrimary ResponsibilityAnalogous Human RoleThe AnalystGeneratorElicit requirements, ask clarifying questions, and draft the initial plan. Focuses on "What" and "Why."Product Manager (PM)The CriticValidatorReview the draft against codebase constraints, security standards, and feasibility. Focuses on "How" and "Risks."Senior Architect / QAThe RefinerSynthesizerMerge the Analyst's draft, the Critic's feedback, and User answers into a final specification.Tech LeadThe CuratorOrchestratorManage the user interface, decide when to ask questions vs. show the plan, and maintain session state.Scrum Master2.2 The Refinement State MachineThe workflow proceeds through a structured state machine, ensuring that no requirement is passed to the coding model until it meets a quality threshold.Ingestion & Contextualization:The Analyst ingests the user's raw prompt. Simultaneously, the system retrieves relevant codebase context (using your existing AI brain). The Analyst uses this to generate a "Preliminary Requirement Draft" (PRD v0.1).The Critique Phase:The Critic analyzes PRD v0.1. It does not look at the user prompt directly; it looks at the interpretation of the prompt. It checks for:Ambiguity: "The plan says 'optimize performance' but defines no metric."Contradiction: "The plan implies a SQL schema change, but the context shows we use MongoDB."Omission: "The plan adds a new API route but forgets authentication middleware.".The Clarification Loop (Maieutic Interaction):If the Critic flags critical ambiguities, the system enters the Maieutic Phase. The Analyst generates specific clarifying questions for the user. These are not generic ("What do you mean?"); they are constrained options ("Do you want to use the existing AuthService or create a new provider?").User Input: "Use existing."Action: This input becomes a hard constraint in the next iteration.Refinement & Synthesis:
The Refiner takes the PRD v0.1, the Critique, and the User's answers to generate PRD v1.0. This artifact is structured (Markdown or Gherkin) and explicitly addresses every point raised by the Critic.Final Approval:The plan is presented to the user in the "Mission Control" UI. The user can approve, reject, or manually edit the plan. Only upon approval is the plan sent to the "Fast Model" for code generation.3. The "Product Manager" Persona: Engineering the AnalystThe Analyst Agent is the user's primary point of contact during refinement. Its behavior must be carefully engineered to avoid the "Yes-Man" syndrome common in LLMs—where the model agrees with vague instructions just to be helpful. Instead, the Analyst must act as a rigorous, inquisitive Technical Product Manager (PM).3.1 Constructing the Persona System PromptResearch shows that adopting a specific persona significantly alters the lexical diversity and reasoning depth of the output. The system prompt for the Analyst must strictly prohibit code generation and enforce a "Requirements First" mindset.System Prompt Template: The "Professional PRD Architect"Role: You are an expert Technical Product Manager with 15+ years of experience in high-scale software development. Your goal is to translate vague user intent into a rigorous, implementation-ready Product Requirement Document (PRD).Directives:Do Not Code: You are strictly forbidden from writing implementation code. Your output is requirements, logic flows, and specifications.Be Skeptical: Assume the user has forgotten edge cases. If the user asks for "file upload," immediately ask about file size limits, supported types, malware scanning, and storage location (S3 vs. Local).Context Aware: You have access to the current codebase summary. If the user asks for a feature that duplicates existing functionality, point it out.Structured Output: Your final output must follow the standard PRD format: Problem Statement, User Stories, Functional Requirements, Non-Functional Requirements, and Acceptance Criteria.Interaction Style: Professional, concise, and structured. Use "Maieutic Prompting" to uncover latent needs..3.2 Maieutic Prompting for ElicitationMaieutic Prompting (derived from the Socratic method) is the technique of using recursive questioning to logically deduce a user's true intent. In software requirements, this means exploring the "Tree of Thoughts" to identify dependencies.The Question Generation Algorithm:Entity Extraction: Identify all nouns in the user prompt (e.g., "User," "Report," "Export").Attribute Verification: For each entity, check if its attributes are defined (e.g., "What fields are in the Report?").Relationship Mapping: Check if relationships are defined (e.g., "Which Users can see which Reports?").Recursive Pruning: If an attribute is undefined, generate a question.User Prompt: "Allow users to delete their accounts."Maieutic Questioning:"Is this a 'soft delete' (flag in DB) or a 'hard delete' (GDPR compliance)?""What happens to the user's associated data (orphaned records)?""Is there a grace period for recovery?".By forcing the user to answer these questions before coding, the Analyst ensures the generated code handles these scenarios, preventing future bugs.3.3 Active Learning LoopsThe refinement process creates an Active Learning Loop where the system learns the specific domain language and preferences of the user.Uncertainty Sampling: The Critic assigns a "Confidence Score" to the draft plan. If the score is low (high ambiguity), the system triggers the Analyst to ask more questions.Feedback Memory: If the user clarifies that "All timestamps must be UTC," this rule is stored in a vector database as a "Project Axiom." Future refinement sessions retrieve this axiom via RAG, allowing the Analyst to apply it automatically without asking again. This creates a "Self-Improving" system that gets smarter with every interaction.4. Contextual Intelligence: Integrating the "AI Brain"Your extension's existing exposure to the codebase is its most valuable asset. However, for refinement, simply dumping raw code into the context window is inefficient and confusing for the model. We need a strategy for Contextual Distillation using Code-Aware Retrieval (RAG) and Abstract Syntax Tree (AST) analysis.4.1 Beyond Text: AST-Based Structural AnalysisText-based RAG (searching for keywords like "login") is insufficient for architectural reasoning. It lacks understanding of structure (inheritance, types, dependencies). To build a "properly spec'd requirement," the system needs to know the interfaces available.The "Skeletonization" Strategy:
To maximize the context window relevance, we should not feed the full implementation code to the Analyst. Instead, we generate Skeleton Files using AST parsing (e.g., via vscode-tree-sitter).Original Code:TypeScript// src/services/AuthService.ts
export class AuthService {
  constructor(private db: Database) {}
  async login(email: string, pass: string): Promise<User> {
    //... 50 lines of validation logic...
    //... database query...
    return user;
  }
}
Skeleton Context (AST-Generated):TypeScriptclass AuthService {
  login(email: string, pass: string): Promise<User>; // Authenticates user
}
This "Skeleton Context" reduces token usage by ~80% while retaining 100% of the architectural information needed for planning. The Analyst can see what methods exist without being distracted by how they are implemented.4.2 The "Software Design Parameters" MatrixTo satisfy the user requirement of considering "all software development and design parameters," the Critic agent acts as a Static Analysis Gatekeeper during the planning phase. It evaluates the plan against a matrix of non-functional requirements.Table 1: Design Parameter Validation MatrixParameter CategoryValidation Logic (Critic Agent)Example CritiqueArchitectural StyleCheck alignment with project patterns (e.g., MVC, Clean Architecture)."The plan puts database logic in the View layer. Move to a Controller/Service."Security (OWASP)Scan for common vulnerabilities in the spec (Injection, AuthZ)."The 'Search' feature lacks input sanitization requirements. Add SQL injection prevention."PerformanceEvaluate complexity (Big O) and resource usage."Looping through 'All Users' will timeout at scale. Require pagination."MaintainabilityCheck for DRY (Don't Repeat Yourself) violations."This logic duplicates UserHelper.ts. Reuse the existing class."Tech Stack ComplianceVerify libraries against package.json."Plan suggests axios, but project uses fetch. Use standard fetch."4.3 RAG for Historical ConsistencyThe "AI Brain" should also index Historical Requirements (past PRDs, commit messages, closed issues). If a user asks to "change the color scheme," RAG can retrieve a past PRD where the "Brand Guidelines" were defined. This ensures the new requirement doesn't violate previously established design rules.5. Artifact Generation: The "Golden Prompt"The ultimate output of the refinement mode is the Golden Prompt—the artifact handed to the "Fast Model" (Coder) to generate the actual code. The format of this artifact is critical for quality. Research suggests two dominant formats: Markdown PRDs and Gherkin Features.5.1 The Markdown PRD (Product Requirement Document)Markdown is the industry standard for documentation and is highly token-efficient for LLMs. Its hierarchical structure (Headings, Lists) helps the model organize its "thoughts".Recommended Structure for the Golden Prompt:Meta-Data: Feature Name, Date, Author (Agent).Context: Summary of relevant existing files (Skeletons).Problem Statement: The "Why."Functional Requirements: Detailed bullet points of behavior.Technical Implementation Plan:Files to Create: List of paths.Files to Modify: List of paths with specific function targets.API Changes: Signatures of new methods.Verification Steps: How to test the feature.5.2 Gherkin for Behavioral RigorFor complex logic, natural language is often too ambiguous. Gherkin (Given-When-Then) provides a rigorous, semi-formal syntax that defines state transitions.Ambiguous Prose: "The user shouldn't be able to login if they are locked out."Rigorous Gherkin:GherkinScenario: Locked Out User Login
  Given the user exists in the database
  And the user's `lockout_until` timestamp is in the future
  When the user submits valid credentials
  Then the system should return a 403 Forbidden status
  And the response body should contain error code `AUTH_LOCKOUT`
Recommendation: The Refinement Mode should generate a Hybrid Artifact. Use Markdown for high-level architecture and Gherkin for specific business logic scenarios. Benchmarks show that LLMs prompted with Gherkin scenarios generate code with 25-30% fewer logic bugs than those prompted with free text.5.3 Pseudocode as "Chain of Thought"Before writing the final code, the Refiner can generate Pseudocode. This acts as an intermediate verification layer. It allows the user to approve the algorithm (e.g., the pricing formula) without getting bogged down in syntax errors. If the pseudocode is correct, the translation to Python/JS is usually trivial for modern models.6. User Experience: Designing "Mission Control" in VS CodeTo truly emulate Google Antigravity, the UX must transcend the linear chat interface. We need a Mission Control Dashboard that visualizes the refinement process.6.1 The Agent Manager ViewUsing the VS Code Webview API or the Secondary Sidebar, create a dashboard that visualizes the state of the agents.Active Agent Indicator: Show which agent is "thinking" (e.g., "Critic is reviewing...").Artifact Projection: When a PRD is drafted, it should not just appear in the chat history. It should open in a Virtual Document (Read-Only Editor) side-by-side with the chat. This allows the user to read the full spec without scrolling through chat bubbles.6.2 Interactive Feedback MechanismsThe "Refinement Mode" relies on high-bandwidth user feedback. Typing "Yes" or "No" is inefficient.Smart Buttons: Use the ChatResponseStream.button() API to offer contextual actions: "Approve Plan," "Revise Architecture," "Add Security Review".Inline Critique: Allow the user to highlight a section of the generated PRD in the Virtual Document and add a comment. The Refiner Agent ingests this comment as a high-priority constraint for the next iteration.6.3 Visualization with Mermaid.jsText descriptions of software architecture are hard to parse mentally. The Analyst should be prompted to generate Mermaid.js diagrams (Flowcharts, Sequence Diagrams, ER Diagrams) within the Markdown PRD.Use Case: A user requests a complex payment flow.Visualization: The agent generates a Sequence Diagram showing the interaction between Client, API, Stripe, and Database.Benefit: The user can instantly spot if a step (e.g., "Send Confirmation Email") is missing or out of order.7. Optimization: Routing Between "Fast" and "Reasoning" ModelsA multi-turn refinement loop is computationally expensive and slow. To make it viable for real-time development, we must implement Model Routing.7.1 The Routing ArchitectureNot every interaction requires a "Reasoning Model" (like OpenAI o1 or Claude 3.5 Sonnet).The Router (Gateway): A lightweight model (e.g., GPT-4o-mini) analyzes the initial prompt.Simple Task (Fix Typo): Route directly to Fast Coder.Complex Task (New Feature): Route to Refinement Loop.The Analyst & Critic (Reasoning Models): These roles require high cognitive capacity to handle Maieutic prompting and AST analysis. They should use the most capable models available.The Curator (Fast Model): Formatting the final Markdown output or summarizing the chat history can be done by a cheaper model to save cost and latency.7.2 Latency ManagementTo mitigate the perceived latency of the "System 2" loop:Streaming Thought Traces: Display the agent's internal monologue (e.g., "Checking authentication constraints...", "Validating against DB schema...") in the UI. This transparency keeps the user engaged and builds trust.Speculative Decoding: While the user is answering a clarifying question, the Analyst can speculatively draft the sections of the PRD that are independent of that answer.8. Technical Implementation RoadmapThis section outlines the concrete steps to build this extension using the VS Code API.Phase 1: Context InfrastructureAST Service: Implement a language-agnostic AST parser (using WASM bindings for Tree-sitter) to generate "Skeleton Contexts."Vector Store: Integrate a local vector database (e.g., HNSWLib) to index the codebase chunks for semantic retrieval.Phase 2: The Agent LogicPrompt Engineering: Implement the system prompts for Analyst, Critic, and Refiner. Use the "Product Manager" persona template defined in Section 3.1.State Machine: Build a TypeScript class RefinementSession that manages the transition between agents.TypeScriptclass RefinementSession {
  async nextStep(userInput: string) {
    if (this.state === 'DRAFTING') return this.analyst.draft(userInput);
    if (this.state === 'CRITIQUING') return this.critic.review(this.currentDraft);
    if (this.state === 'REFINING') return this.refiner.polish(this.critique, userInput);
  }
}
Phase 3: The Mission Control UIChat Participant: Register the extension using vscode.chat.createChatParticipant('antigravity.refine', handler).Rich Rendering: Implement a markdown renderer that supports Mermaid.js diagrams and renders Gherkin blocks with syntax highlighting.Artifact Manager: Create a TreeView in the sidebar to list generated PRDs and allow users to "Load" them into the chat context.9. ConclusionThe "Refinement Mode" you propose represents the future of IDEs. By shifting focus from "generating code" to "generating requirements," you address the fundamental flaw of current AI tools: the ambiguity of human intent.The architecture outlined in this report—anchored by the Critic-Refiner Loop, fueled by Maieutic Prompting, and grounded in Code-Aware AST Analysis—provides a robust blueprint for building a "Mission Control" center within VS Code. This system elevates the user from a "Coder" to an "Architect," enabling them to define high-quality, design-compliant software specifications that the AI can execute with precision. This is not just a feature; it is a new paradigm for software engineering in the age of Agentic AI.10. References & Data SourcesThis architectural blueprint synthesizes insights from the following research materials:Agentic Architectures: Prompt Engineering Strategies: Google Antigravity & IDX: Context & AST Analysis: Output Formats (PRD/Gherkin): VS Code Extension API: 